{"title":"Notes: Few concepts of machine learning","markdown":{"yaml":{"layout":"post","title":"Notes: Few concepts of machine learning","categories":["machine-learning"],"author":"Akhilesh","date":"2017-01-20","image":"image.png"},"containsRefs":false,"markdown":"\n\nNotes on a few ML concepts.\n\n*Deduction*: Given the rule and the cause, deduce the effect.\n\n*Induction*: Given a cause and an effect,  induce a rule.\n\n*Abduction*: Given a rule and an effect, abduce a cause.\n\n*TAXONOMY*\n\nWhat?   –  Parameters, structure, hidden concepts\n\nWhat from?   –   Supervised, Unsupervised, Reinforcement\n\nWhat for?    –     prediction, diagnostics, summarization\n\nHow?     –     passive, active, online, offline\n\nOutputs?   –      Classification, Regression\n\nDetails?     –    Generative, Discriminative\n\nOccom’s Razor – Everything else being equal, choose the less complex hypothesis.\n\nThe Ultimate goal of Machine Learning is to have data models that can learn and improve overtime. \n\n**Evaluation Metrics**\n\nLearn from data to make predictions.\n\nClassification is about deciding which categories new instances belong to. Then when we see new objects we can use their features to guess which class they belong to.\n\nIn regression, we want to make a prediction on continuous data.\n\nIn classification, we want to see how often a model correctly or incorrectly identifies a new example, whereas, in regression we might be more interested to see how far off the model’s prediction is true from true value.\n\nClassification ⇒ Accuracy, precision, recall and F-score.\n\nRegression ⇒ mean absolute error and mean square error.\n\nShort comings of accuracy:\n\n- Not ideal for skewed classes\n- may want to err on side of guessing innocent.\n- may want to err on the side of guessing guilty.\n\nCauses of Error:\n\n- Bias due to a model being unable to represent the complexity of the underlying data.\n\n- Variance due to a model being overly sensitive to the limited data it has been trained on.\n\n- Bias occurs when a model has enough data but is not complex enough to capture the underlying relationships. As a result, the model consistently and systematically misrepresents the data, leading to low accuracy in prediction. This is known as Underfitting. To overcome error from bias, we need more complex model.\n\n- Variance is a measure of how much the predictions vary for any given test sample. High sensitivity to the training set is also known as Overfitting. Occurs when the model is too complex.\n\n- We can typically reduce the variability of a model’s predictions and increase precision by training on more data. If more data is unavailable, we can also control variance by limiting our model’s complexity .\n\nData Types:\n\n- Numeric data\n- Categorical data\n- Time-Series data\n\n**Curse of Dimensionality**\n\nAs the number of features or dimensions grows, the amount of data we need to generalize accurately grows exponentially.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"2017-01-20-ml-concepts.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"journal","title-block-banner":true,"layout":"post","title":"Notes: Few concepts of machine learning","categories":["machine-learning"],"author":"Akhilesh","date":"2017-01-20","image":"image.png"},"extensions":{"book":{"multiFile":true}}}}}